import { NextRequest, NextResponse } from "next/server"
import OpenAI from "openai"

interface ChatMessage {
  role: "user" | "assistant"
  content: string
}

export async function POST(request: NextRequest) {
  try {
    const { documentText, question, chatHistory } = await request.json()

    if (!documentText || !documentText.trim()) {
      return NextResponse.json(
        { error: "ë¬¸ì„œ í…ìŠ¤íŠ¸ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤." },
        { status: 400 }
      )
    }

    if (!question || !question.trim()) {
      return NextResponse.json(
        { error: "ì§ˆë¬¸ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤." },
        { status: 400 }
      )
    }

    // OpenAI API í‚¤ í™•ì¸
    const apiKey = process.env.OPENAI_API_KEY
    if (!apiKey) {
      return NextResponse.json({
        answer: "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ AI ë‹µë³€ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n.env.local íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì¶”ê°€í•˜ê³  ì„œë²„ë¥¼ ì¬ì‹œì‘í•´ì£¼ì„¸ìš”.\n\në¬¸ì„œ ë‚´ìš©ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰ ê¸°ëŠ¥ì€ ì¶”í›„ ì¶”ê°€ ì˜ˆì •ì…ë‹ˆë‹¤.",
      })
    }

    const openai = new OpenAI({ apiKey })

    // ë¬¸ì„œê°€ ë„ˆë¬´ ê¸¸ë©´ ì•ë¶€ë¶„ë§Œ ì‚¬ìš© (ì•½ 3000ì)
    const truncatedDoc = documentText.length > 3000
      ? documentText.substring(0, 3000) + "..."
      : documentText

    // ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ OpenAI í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    const messages: any[] = [
      {
        role: "system",
        content: `ë‹¹ì‹ ì€ ë¬¸ì„œ ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ë‹¤ìŒì€ ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ ë¬¸ì„œ ë‚´ìš©ì…ë‹ˆë‹¤:

${truncatedDoc}

ìœ„ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ìì„¸í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ "ë¬¸ì„œì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•´ì£¼ì„¸ìš”.`,
      },
    ]

    // ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶”ê°€ (ìµœê·¼ 5ê°œë§Œ)
    if (chatHistory && Array.isArray(chatHistory)) {
      const recentHistory = chatHistory.slice(-5)
      messages.push(...recentHistory.map((msg: ChatMessage) => ({
        role: msg.role,
        content: msg.content,
      })))
    }

    // í˜„ì¬ ì§ˆë¬¸ ì¶”ê°€
    messages.push({
      role: "user",
      content: question,
    })

    // OpenAI API í˜¸ì¶œ
    const completion = await openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages,
      temperature: 0.7,
      max_tokens: 500,
    })

    const answer = completion.choices[0]?.message?.content || "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    // ì‚¬ìš©ëŸ‰ ë¡œê¹…
    console.log("ğŸ“Š [ì±„íŒ… Q&A] í† í° ì‚¬ìš©ëŸ‰:", {
      ì…ë ¥_í† í°: completion.usage?.prompt_tokens || 0,
      ì¶œë ¥_í† í°: completion.usage?.completion_tokens || 0,
      ì´_í† í°: completion.usage?.total_tokens || 0,
      ë¬¸ì„œ_ê¸¸ì´: documentText.length,
      ì²˜ë¦¬_ë¬¸ì„œ_ê¸¸ì´: truncatedDoc.length,
      ì§ˆë¬¸_ê¸¸ì´: question.length,
      ëŒ€í™”_ê¸°ë¡: chatHistory?.length || 0,
      ëª¨ë¸: "gpt-3.5-turbo",
    })

    const estimatedCost = (
      (completion.usage?.prompt_tokens || 0) * 0.50 / 1000000 +
      (completion.usage?.completion_tokens || 0) * 1.50 / 1000000
    ).toFixed(6)

    console.log(`ğŸ’µ ì˜ˆìƒ ë¹„ìš©: $${estimatedCost}`)

    return NextResponse.json({
      answer,
    })
  } catch (error: any) {
    console.error("OpenAI Chat API error:", error)

    // OpenAI API ì—ëŸ¬ ì²˜ë¦¬
    if (error.status === 401) {
      return NextResponse.json(
        { error: "OpenAI API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤." },
        { status: 500 }
      )
    }

    if (error.status === 429) {
      return NextResponse.json(
        { error: "OpenAI API ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤." },
        { status: 429 }
      )
    }

    return NextResponse.json(
      { error: "ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤." },
      { status: 500 }
    )
  }
}
