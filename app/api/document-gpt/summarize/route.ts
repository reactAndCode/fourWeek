import { NextRequest, NextResponse } from "next/server"
import OpenAI from "openai"

export async function POST(request: NextRequest) {
  try {
    const { text } = await request.json()

    if (!text || !text.trim()) {
      return NextResponse.json(
        { error: "ë¬¸ì„œ í…ìŠ¤íŠ¸ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤." },
        { status: 400 }
      )
    }

    // OpenAI API í‚¤ í™•ì¸
    const apiKey = process.env.OPENAI_API_KEY
    if (!apiKey) {
      // API í‚¤ê°€ ì—†ìœ¼ë©´ ê°„ë‹¨í•œ ìš”ì•½ ì œê³µ
      const wordCount = text.length
      const preview = text.substring(0, 200) + (text.length > 200 ? "..." : "")

      return NextResponse.json({
        summary: `ë¬¸ì„œ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: ${preview}\n\n(OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ AI ìš”ì•½ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤)`,
        keyPoints: [
          "OpenAI API í‚¤ë¥¼ .env.localì— ì„¤ì •í•˜ë©´ AI ìš”ì•½ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤",
          "í˜„ì¬ëŠ” ë¬¸ì„œ ì—…ë¡œë“œì™€ ì§ˆë¬¸ ê¸°ëŠ¥ë§Œ ì œí•œì ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤",
        ],
        wordCount,
      })
    }

    const openai = new OpenAI({ apiKey })

    // í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ì•ë¶€ë¶„ë§Œ ì‚¬ìš© (ì•½ 4000ì)
    const truncatedText = text.length > 4000 ? text.substring(0, 4000) + "..." : text

    // OpenAI API í˜¸ì¶œ - ë¬¸ì„œ ìš”ì•½
    const completion = await openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: [
        {
          role: "system",
          content:
            "ë‹¹ì‹ ì€ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³  ìš”ì•½í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë¬¸ì„œì˜ í•µì‹¬ ë‚´ìš©ì„ ê°„ê²°í•˜ê²Œ ìš”ì•½í•˜ê³ , ì£¼ìš” í¬ì¸íŠ¸ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.",
        },
        {
          role: "user",
          content: `ë‹¤ìŒ ë¬¸ì„œë¥¼ ìš”ì•½í•˜ê³  ì£¼ìš” ë‚´ìš©ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”:\n\n${truncatedText}`,
        },
      ],
      temperature: 0.7,
      max_tokens: 500,
    })

    const summaryContent = completion.choices[0]?.message?.content || ""

    // ì‚¬ìš©ëŸ‰ ë¡œê¹…
    console.log("ğŸ“Š [ë¬¸ì„œ ìš”ì•½] í† í° ì‚¬ìš©ëŸ‰:", {
      ì…ë ¥_í† í°: completion.usage?.prompt_tokens || 0,
      ì¶œë ¥_í† í°: completion.usage?.completion_tokens || 0,
      ì´_í† í°: completion.usage?.total_tokens || 0,
      ì›ë³¸_ë¬¸ììˆ˜: text.length,
      ì²˜ë¦¬_ë¬¸ììˆ˜: truncatedText.length,
      ëª¨ë¸: "gpt-3.5-turbo",
    })

    // ì£¼ìš” í¬ì¸íŠ¸ ì¶”ì¶œ
    const keyPointsCompletion = await openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: [
        {
          role: "system",
          content:
            "ë¬¸ì„œì˜ ì£¼ìš” í¬ì¸íŠ¸ë¥¼ 3-5ê°œì˜ ê°„ê²°í•œ ë¬¸ì¥ìœ¼ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”. ê° í¬ì¸íŠ¸ëŠ” í•œ ì¤„ë¡œ ì‘ì„±í•˜ê³ , ë²ˆí˜¸ë‚˜ ë¶ˆë¦¿ ì—†ì´ í…ìŠ¤íŠ¸ë§Œ ì‘ì„±í•´ì£¼ì„¸ìš”.",
        },
        {
          role: "user",
          content: `ë‹¤ìŒ ë¬¸ì„œì˜ ì£¼ìš” í¬ì¸íŠ¸ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”:\n\n${truncatedText}`,
        },
      ],
      temperature: 0.5,
      max_tokens: 300,
    })

    const keyPointsContent = keyPointsCompletion.choices[0]?.message?.content || ""
    const keyPoints = keyPointsContent
      .split("\n")
      .filter((line) => line.trim().length > 0)
      .map((line) => line.replace(/^[0-9]+\.\s*/, "").replace(/^[-â€¢]\s*/, "").trim())
      .slice(0, 5)

    // ì£¼ìš” í¬ì¸íŠ¸ ì¶”ì¶œ ì‚¬ìš©ëŸ‰ ë¡œê¹…
    console.log("ğŸ“Š [ì£¼ìš” í¬ì¸íŠ¸] í† í° ì‚¬ìš©ëŸ‰:", {
      ì…ë ¥_í† í°: keyPointsCompletion.usage?.prompt_tokens || 0,
      ì¶œë ¥_í† í°: keyPointsCompletion.usage?.completion_tokens || 0,
      ì´_í† í°: keyPointsCompletion.usage?.total_tokens || 0,
      ëª¨ë¸: "gpt-3.5-turbo",
    })

    // ì „ì²´ ì‚¬ìš©ëŸ‰ ê³„ì‚°
    const totalUsage = {
      ì´_ì…ë ¥_í† í°: (completion.usage?.prompt_tokens || 0) + (keyPointsCompletion.usage?.prompt_tokens || 0),
      ì´_ì¶œë ¥_í† í°: (completion.usage?.completion_tokens || 0) + (keyPointsCompletion.usage?.completion_tokens || 0),
      ì´_í† í°: (completion.usage?.total_tokens || 0) + (keyPointsCompletion.usage?.total_tokens || 0),
    }

    console.log("ğŸ’° [ì´ ì‚¬ìš©ëŸ‰]", totalUsage)
    console.log(`ğŸ’µ ì˜ˆìƒ ë¹„ìš©: $${(totalUsage.ì´_ì…ë ¥_í† í° * 0.50 / 1000000 + totalUsage.ì´_ì¶œë ¥_í† í° * 1.50 / 1000000).toFixed(6)}`)

    return NextResponse.json({
      summary: summaryContent,
      keyPoints,
      wordCount: text.length,
    })
  } catch (error: any) {
    console.error("OpenAI API error:", error)

    // OpenAI API ì—ëŸ¬ ì²˜ë¦¬
    if (error.status === 401) {
      return NextResponse.json(
        { error: "OpenAI API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤." },
        { status: 500 }
      )
    }

    if (error.status === 429) {
      return NextResponse.json(
        { error: "OpenAI API ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤." },
        { status: 429 }
      )
    }

    return NextResponse.json(
      { error: "ë¬¸ì„œ ìš”ì•½ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤." },
      { status: 500 }
    )
  }
}
