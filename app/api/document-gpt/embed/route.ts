import { NextRequest, NextResponse } from "next/server"
import { OpenAIEmbeddings } from "@langchain/openai"
import { RecursiveCharacterTextSplitter } from "@langchain/textsplitters"
import { MemoryVectorStore } from "@langchain/classic/vectorstores/memory"
import { randomUUID } from "crypto"
import path from "path"
import fs from "fs/promises"
import os from "os"

export async function POST(request: NextRequest) {
  try {
    const { text } = await request.json()

    if (!text || !text.trim()) {
      return NextResponse.json(
        { error: "ë¬¸ì„œ í…ìŠ¤íŠ¸ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤." },
        { status: 400 }
      )
    }

    // OpenAI API í‚¤ í™•ì¸
    const apiKey = process.env.OPENAI_API_KEY
    if (!apiKey) {
      return NextResponse.json(
        { error: "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤." },
        { status: 500 }
      )
    }

    // ë¬¸ì„œ ID ìƒì„±
    const documentId = randomUUID()

    console.log("ğŸ“„ [ë²¡í„° ì„ë² ë”©] ë¬¸ì„œ ì²˜ë¦¬ ì‹œì‘:", {
      documentId,
      ì›ë³¸_ê¸¸ì´: text.length,
    })

    // 1. í…ìŠ¤íŠ¸ ë¶„í•  (ì²­í¬ë¡œ ë‚˜ëˆ„ê¸°)
    const textSplitter = new RecursiveCharacterTextSplitter({
      chunkSize: 1000, // ì²­í¬ í¬ê¸°
      chunkOverlap: 200, // ì²­í¬ ê°„ ê²¹ì¹¨
    })

    const docs = await textSplitter.createDocuments([text])

    console.log("âœ‚ï¸ [í…ìŠ¤íŠ¸ ë¶„í• ] ì™„ë£Œ:", {
      ì´_ì²­í¬_ìˆ˜: docs.length,
      í‰ê· _ì²­í¬_ê¸¸ì´: Math.round(text.length / docs.length),
    })

    // 2. OpenAI ì„ë² ë”© ìƒì„±
    const embeddings = new OpenAIEmbeddings({
      openAIApiKey: apiKey,
      modelName: "text-embedding-3-small", // ë¹„ìš© íš¨ìœ¨ì ì¸ ëª¨ë¸
    })

    // 3. ë©”ëª¨ë¦¬ ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
    const vectorStore = await MemoryVectorStore.fromDocuments(docs, embeddings)

    console.log("ğŸ”¢ [ì„ë² ë”© ìƒì„±] ì™„ë£Œ:", {
      ë²¡í„°_ì°¨ì›: 1536, // text-embedding-3-smallì˜ ì°¨ì›
      ì´_ë²¡í„°_ìˆ˜: docs.length,
    })

    // 4. ë²¡í„° ìŠ¤í† ì–´ë¥¼ JSONìœ¼ë¡œ ì§ë ¬í™”í•˜ì—¬ íŒŒì¼ ì‹œìŠ¤í…œì— ì €ì¥
    const tempDir = os.tmpdir()
    const vectorDir = path.join(tempDir, "vector-stores")

    // ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
    try {
      await fs.mkdir(vectorDir, { recursive: true })
    } catch (error) {
      console.error("ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨:", error)
    }

    const indexPath = path.join(vectorDir, `${documentId}.json`)

    // ë²¡í„° ìŠ¤í† ì–´ ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ ì €ì¥
    const vectorStoreData = {
      memoryVectors: vectorStore.memoryVectors,
      _vectorstoreType: "memory"
    }
    await fs.writeFile(indexPath, JSON.stringify(vectorStoreData), "utf-8")

    console.log("ğŸ’¾ [ì¸ë±ìŠ¤ ì €ì¥] ì™„ë£Œ:", {
      ì €ì¥_ê²½ë¡œ: indexPath,
    })

    // ì„ë² ë”© ë¹„ìš© ê³„ì‚° (ëŒ€ëµì )
    const estimatedTokens = Math.ceil(text.length / 4) // ëŒ€ëµ 4ì = 1í† í°
    const estimatedCost = (estimatedTokens * 0.02) / 1000000 // text-embedding-3-small: $0.02 / 1M tokens

    console.log("ğŸ’° [ì„ë² ë”© ë¹„ìš©] ì˜ˆìƒ:", {
      ì˜ˆìƒ_í† í°: estimatedTokens,
      ì˜ˆìƒ_ë¹„ìš©: `$${estimatedCost.toFixed(6)}`,
      ëª¨ë¸: "text-embedding-3-small",
    })

    return NextResponse.json({
      success: true,
      documentId,
      chunksCount: docs.length,
      indexPath,
    })
  } catch (error: any) {
    console.error("FAISS embedding error:", error)

    // OpenAI API ì—ëŸ¬ ì²˜ë¦¬
    if (error.status === 401) {
      return NextResponse.json(
        { error: "OpenAI API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤." },
        { status: 500 }
      )
    }

    if (error.status === 429) {
      return NextResponse.json(
        { error: "OpenAI API ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤." },
        { status: 429 }
      )
    }

    return NextResponse.json(
      { error: `ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${error.message}` },
      { status: 500 }
    )
  }
}
