import { NextRequest, NextResponse } from "next/server"
import OpenAI from "openai"
import { createClient } from "@supabase/supabase-js"

interface ChatMessage {
  role: "user" | "assistant"
  content: string
}

export async function POST(request: NextRequest) {
  try {
    const { documentId, question, chatHistory } = await request.json()

    if (!documentId || !documentId.trim()) {
      return NextResponse.json(
        { error: "ë¬¸ì„œ IDê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤." },
        { status: 400 }
      )
    }

    if (!question || !question.trim()) {
      return NextResponse.json(
        { error: "ì§ˆë¬¸ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤." },
        { status: 400 }
      )
    }

    // OpenAI API í‚¤ í™•ì¸
    const openaiKey = process.env.OPENAI_API_KEY
    if (!openaiKey) {
      return NextResponse.json(
        { error: "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤." },
        { status: 500 }
      )
    }

    // Supabase í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
    const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL
    const supabaseKey = process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY
    if (!supabaseUrl || !supabaseKey) {
      return NextResponse.json(
        { error: "Supabase í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤." },
        { status: 500 }
      )
    }

    const supabase = createClient(supabaseUrl, supabaseKey)
    const openai = new OpenAI({ apiKey: openaiKey })

    console.log("ğŸ” [ë²¡í„° ì¿¼ë¦¬] ê²€ìƒ‰ ì‹œì‘:", {
      documentId,
      ì§ˆë¬¸_ê¸¸ì´: question.length,
    })

    // 1. ì§ˆë¬¸ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
    const embeddingResponse = await openai.embeddings.create({
      model: "text-embedding-ada-002",
      input: question,
    })

    const queryEmbedding = embeddingResponse.data[0].embedding
    const queryTokens = embeddingResponse.usage.total_tokens

    console.log("ğŸ”¢ [ì§ˆë¬¸ ì„ë² ë”©] ì™„ë£Œ:", {
      ì„ë² ë”©_ì°¨ì›: queryEmbedding.length,
      ì‚¬ìš©_í† í°: queryTokens,
    })

    // 2. Supabaseì—ì„œ ìœ ì‚¬í•œ ì²­í¬ ê²€ìƒ‰ (RPC í•¨ìˆ˜ í˜¸ì¶œ)
    const { data: similarChunks, error: searchError } = await supabase.rpc(
      "match_document_chunks",
      {
        query_embedding: queryEmbedding,
        filter_document_id: documentId,
        match_threshold: 0.7, // ìœ ì‚¬ë„ ì„ê³„ê°’ (0.7 ì´ìƒë§Œ)
        match_count: 4, // ìƒìœ„ 4ê°œ ì²­í¬
      }
    )

    if (searchError) {
      console.error("âŒ [ìœ ì‚¬ë„ ê²€ìƒ‰] ì‹¤íŒ¨:", searchError)
      return NextResponse.json(
        { error: `ìœ ì‚¬ë„ ê²€ìƒ‰ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: ${searchError.message}` },
        { status: 500 }
      )
    }

    if (!similarChunks || similarChunks.length === 0) {
      console.warn("âš ï¸ [ìœ ì‚¬ë„ ê²€ìƒ‰] ê´€ë ¨ ì²­í¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
      return NextResponse.json({
        answer: "ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì„ ë¬¸ì„œì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì§ˆë¬¸í•´ë³´ì„¸ìš”.",
        retrievedChunks: 0,
      })
    }

    console.log("ğŸ“Š [ìœ ì‚¬ë„ ê²€ìƒ‰] ì™„ë£Œ:", {
      ê²€ìƒ‰ëœ_ì²­í¬_ìˆ˜: similarChunks.length,
      ìœ ì‚¬ë„_ì ìˆ˜: similarChunks.map((c: any) => c.similarity.toFixed(4)),
    })

    // 3. ê²€ìƒ‰ëœ ì²­í¬ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ê²°í•©
    const context = similarChunks
      .map((chunk: any, idx: number) => {
        return `[ì²­í¬ ${idx + 1}] (ìœ ì‚¬ë„: ${(chunk.similarity * 100).toFixed(1)}%)\n${chunk.content}`
      })
      .join("\n\n")

    console.log("ğŸ“ [ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±] ì™„ë£Œ:", {
      ì´_ì»¨í…ìŠ¤íŠ¸_ê¸¸ì´: context.length,
    })

    // 4. OpenAIë¡œ ë‹µë³€ ìƒì„±
    const messages: any[] = [
      {
        role: "system",
        content: `ë‹¹ì‹ ì€ ë¬¸ì„œ ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ì„œì˜ ì¼ë¶€ì…ë‹ˆë‹¤:

${context}

ìœ„ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ìì„¸í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.
ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ "ì œê³µëœ ë¬¸ì„œì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•´ì£¼ì„¸ìš”.
ë‹µë³€ ì‹œ ì–´ëŠ ì²­í¬ì—ì„œ ì •ë³´ë¥¼ ì°¾ì•˜ëŠ”ì§€ ì–¸ê¸‰í•˜ë©´ ë” ì¢‹ìŠµë‹ˆë‹¤.`,
      },
    ]

    // ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶”ê°€ (ìµœê·¼ 3ê°œë§Œ)
    if (chatHistory && Array.isArray(chatHistory)) {
      const recentHistory = chatHistory.slice(-3)
      messages.push(
        ...recentHistory.map((msg: ChatMessage) => ({
          role: msg.role,
          content: msg.content,
        }))
      )
    }

    // í˜„ì¬ ì§ˆë¬¸ ì¶”ê°€
    messages.push({
      role: "user",
      content: question,
    })

    // OpenAI API í˜¸ì¶œ
    const completion = await openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages,
      temperature: 0.7,
      max_tokens: 500,
    })

    const answer = completion.choices[0]?.message?.content || "ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    // ì‚¬ìš©ëŸ‰ ë¡œê¹…
    console.log("ğŸ“Š [ë²¡í„° Q&A] í† í° ì‚¬ìš©ëŸ‰:", {
      ì§ˆë¬¸_ì„ë² ë”©_í† í°: queryTokens,
      ë‹µë³€_ì…ë ¥_í† í°: completion.usage?.prompt_tokens || 0,
      ë‹µë³€_ì¶œë ¥_í† í°: completion.usage?.completion_tokens || 0,
      ë‹µë³€_ì´_í† í°: completion.usage?.total_tokens || 0,
      ì»¨í…ìŠ¤íŠ¸_ê¸¸ì´: context.length,
      ì§ˆë¬¸_ê¸¸ì´: question.length,
      ëŒ€í™”_ê¸°ë¡: chatHistory?.length || 0,
      ëª¨ë¸: "gpt-3.5-turbo",
    })

    // ë¹„ìš© ê³„ì‚°
    const queryEmbeddingCost = (queryTokens * 0.10) / 1000000 // ì§ˆë¬¸ ì„ë² ë”© ë¹„ìš©
    const chatCost =
      ((completion.usage?.prompt_tokens || 0) * 0.50) / 1000000 +
      ((completion.usage?.completion_tokens || 0) * 1.50) / 1000000

    const totalCost = queryEmbeddingCost + chatCost

    console.log("ğŸ’µ ë¹„ìš© ìƒì„¸:", {
      ì§ˆë¬¸_ì„ë² ë”©: `$${queryEmbeddingCost.toFixed(6)}`,
      GPT_ë‹µë³€: `$${chatCost.toFixed(6)}`,
      ì´_ë¹„ìš©: `$${totalCost.toFixed(6)}`,
    })

    return NextResponse.json({
      answer,
      retrievedChunks: similarChunks.length,
    })
  } catch (error: any) {
    console.error("âŒ [ë²¡í„° ì¿¼ë¦¬ ì˜¤ë¥˜]", error)

    // OpenAI API ì—ëŸ¬ ì²˜ë¦¬
    if (error.status === 401) {
      return NextResponse.json(
        { error: "OpenAI API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤." },
        { status: 500 }
      )
    }

    if (error.status === 429) {
      return NextResponse.json(
        { error: "OpenAI API ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤." },
        { status: 429 }
      )
    }

    return NextResponse.json(
      { error: `ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${error.message}` },
      { status: 500 }
    )
  }
}
